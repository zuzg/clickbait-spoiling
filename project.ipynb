{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickbait spoiling üñ±Ô∏è\n",
    "Task description: https://pan.webis.de/semeval23/pan23-web/clickbait-challenge.html (task 2)\n",
    "\n",
    "Data: https://zenodo.org/record/6362726#.YsbdSTVBzrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "from src.data import read_data, save_df_to_jsonl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data('data/train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0af11f6b-c889-4520-9372-66ba25cb7657</td>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>[how about that morning we go throw?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1a1f63d-8853-4a11-89e8-6b2952a393ec</td>\n",
       "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
       "      <td>NASA sets date for full recovery of ozone hole</td>\n",
       "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
       "      <td>[2070]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008b7b19-0445-4e16-8f9e-075b73f80ca4</td>\n",
       "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
       "      <td>This is what makes employees happy -- and it's...</td>\n",
       "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
       "      <td>[intellectual stimulation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31ecf93c-3e21-4c80-949b-aa549a046b93</td>\n",
       "      <td>‚ÄòFollow your passion‚Äô is wrong, here are 7 hab...</td>\n",
       "      <td>Passion is overrated ‚Äî¬†7 work habits you need ...</td>\n",
       "      <td>‚ÄòFollow your passion‚Äô is wrong, here are 7 hab...</td>\n",
       "      <td>[Purpose connects us to something bigger and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31b108a3-c828-421a-a4b9-cf651e9ac859</td>\n",
       "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
       "      <td>The perfect way to cook rice so that it's perf...</td>\n",
       "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
       "      <td>[in a rice cooker]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid  \\\n",
       "0  0af11f6b-c889-4520-9372-66ba25cb7657   \n",
       "1  b1a1f63d-8853-4a11-89e8-6b2952a393ec   \n",
       "2  008b7b19-0445-4e16-8f9e-075b73f80ca4   \n",
       "3  31ecf93c-3e21-4c80-949b-aa549a046b93   \n",
       "4  31b108a3-c828-421a-a4b9-cf651e9ac859   \n",
       "\n",
       "                                               title  \\\n",
       "0  Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1  Hole In Ozone Layer Expected To Make Full Reco...   \n",
       "2  Intellectual Stimulation Trumps Money For Empl...   \n",
       "3  ‚ÄòFollow your passion‚Äô is wrong, here are 7 hab...   \n",
       "4  Revealed: The perfect way to cook rice so that...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     NASA sets date for full recovery of ozone hole   \n",
       "2  This is what makes employees happy -- and it's...   \n",
       "3  Passion is overrated ‚Äî¬†7 work habits you need ...   \n",
       "4  The perfect way to cook rice so that it's perf...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1  Hole In Ozone Layer Expected To Make Full Reco...   \n",
       "2  Intellectual Stimulation Trumps Money For Empl...   \n",
       "3  ‚ÄòFollow your passion‚Äô is wrong, here are 7 hab...   \n",
       "4  Revealed: The perfect way to cook rice so that...   \n",
       "\n",
       "                                             spoiler  \n",
       "0              [how about that morning we go throw?]  \n",
       "1                                             [2070]  \n",
       "2                         [intellectual stimulation]  \n",
       "3  [Purpose connects us to something bigger and i...  \n",
       "4                                 [in a rice cooker]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3200 entries, 0 to 3199\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   uuid      3200 non-null   object\n",
      " 1   title     3200 non-null   object\n",
      " 2   question  3200 non-null   object\n",
      " 3   context   3200 non-null   object\n",
      " 4   spoiler   3200 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 125.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering model\n",
    "Firstly, we will verify existing approach - question answering pipeline with roberta-base-squad2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32f15e99797435187cd2145984200fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_pipeline = pipeline(model=\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify sample spoilers and assess accuracy\n",
    "For now, simply check if real and generated spoiler intersect with at least one word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct | generated spoiler | true spoiler\n",
      "1 let‚Äôs go throw ['how about that morning we go throw?']\n",
      "1 2070 ['2070']\n",
      "0 money ['intellectual stimulation']\n",
      "0 Adopting a peripheral perspective ['Purpose connects us to something bigger and in doing so makes us right sized', 'be ruthless with your \"No‚Äôs.\"', 'Practice means greatness is doable ... one tiny step after another', 'planning of the SMART goal and number-crunching variety', 'Objectivity ‚Äî the ability to see the world as it truly is']\n",
      "0 I follow these steps ['in a rice cooker']\n",
      "1 you'll have to buy new ones [\"Apple says that if AirPods are lost or stolen, you'll have to buy new ones, just like any other Apple product.\"]\n",
      "0 Is he constantly hungover ['\"The more good games I had in them, the more I got used to them.']\n",
      "1 -10 degrees Celsius,\" said HaÃànninen. ['rainbow colours in the sky and a halo spanning 360 degrees']\n",
      "0 5/5 say yes ['Red wine is clearly the drink of choice if you are doing light to moderate drinking for your health, and daily consumption just before or with the evening meal may be the most protective pattern,\" O‚ÄôKeefe says']\n",
      "1 Sriracha Hot Chili Sauce ['Sriracha Hot Chili Sauce', \"Frank's RedHot Original Sauce\", 'Cholula Chili Garlic', 'Louisiana Hot Sauce', 'CaJohns Bourbon Infused Chipotle-Haba√±ero Sauce']\n",
      "\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "preds = dict({\"uuid\" : [],\n",
    "             \"spoiler\": []})\n",
    "\n",
    "print(\"correct | generated spoiler | true spoiler\")\n",
    "for i, uuid, question, context, spoiler in zip(range(10), train.uuid, train.question, train.context, train.spoiler):\n",
    "    answer = qa_pipeline(\n",
    "        question=question,\n",
    "        context=context,\n",
    "    )\n",
    "    if any(word in spoiler[0].split() for word in answer['answer'].split()):\n",
    "        score.append(1)\n",
    "    else:\n",
    "        score.append(0)\n",
    "    print(score[i], answer['answer'], spoiler)\n",
    "    preds[\"uuid\"].append(uuid)\n",
    "    preds[\"spoiler\"].append(answer['answer'])\n",
    "\n",
    "pred_df = pd.DataFrame.from_dict(preds)\n",
    "print(f\"\\nAccuracy: {sum(score)/len(score)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is definitely room for improvement, some generated spoiler are perfectly correct, but some are totally missed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We will use script provided by SemEval23 organizers to evaluate our approaches. The scripts takes data in the form of JSONL file with columns `uuid` and `spoiler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_jsonl(train.iloc[:10], \"data/test_true.jsonl\")\n",
    "save_df_to_jsonl(pred_df, \"data/test_output.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [\u001b[92mo\u001b[0m] The file data/test_output.jsonl is in JSONL format.\n",
      "  [\u001b[92mo\u001b[0m] The file data/test_true.jsonl is in JSONL format.\n",
      "  [\u001b[92mo\u001b[0m] Spoiler generations have correct format. Found 10\n",
      "Run evaluation for all-spoilers\n",
      "  [\u001b[92mo\u001b[0m] Spoiler generations have correct format. Found 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['java', '-Xmx2G', '-jar', '/meteor-1.5.jar', 'C:\\\\Users\\\\zgawrysi\\\\AppData\\\\Local\\\\Temp\\\\tmpcc9yg6n1/truths.txt', 'C:\\\\Users\\\\zgawrysi\\\\AppData\\\\Local\\\\Temp\\\\tmpcc9yg6n1/preds.txt', '-l', 'en', '-norm', '-t', 'adq']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\UNI\\VI\\nlp\\project\\clickbait-spoiling\\src\\evaluation.py:375\u001b[0m\n\u001b[0;32m    368\u001b[0m input_run \u001b[39m=\u001b[39m load_json_lines(args\u001b[39m.\u001b[39minput_run)\n\u001b[0;32m    369\u001b[0m ground_truth_spoilers \u001b[39m=\u001b[39m (\n\u001b[0;32m    370\u001b[0m     \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    371\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mground_truth_spoilers\n\u001b[0;32m    372\u001b[0m     \u001b[39melse\u001b[39;00m load_json_lines(args\u001b[39m.\u001b[39mground_truth_spoilers)\n\u001b[0;32m    373\u001b[0m )\n\u001b[1;32m--> 375\u001b[0m eval_task_2(\n\u001b[0;32m    376\u001b[0m     input_run,\n\u001b[0;32m    377\u001b[0m     ground_truth_spoilers,\n\u001b[0;32m    378\u001b[0m     args\u001b[39m.\u001b[39;49moutput_prototext,\n\u001b[0;32m    379\u001b[0m )\n",
      "File \u001b[1;32m~\\UNI\\VI\\nlp\\project\\clickbait-spoiling\\src\\evaluation.py:354\u001b[0m, in \u001b[0;36meval_task_2\u001b[1;34m(input_run, ground_truth_spoilers, output_file)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRun evaluation for \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m display_name)\n\u001b[0;32m    350\u001b[0m     filtered_ground_truth_spoilers \u001b[39m=\u001b[39m spoiler_generations_to_map(\n\u001b[0;32m    351\u001b[0m         deepcopy(ground_truth_spoilers), expected_spoiler_type\u001b[39m=\u001b[39mtag_name\n\u001b[0;32m    352\u001b[0m     )\n\u001b[1;32m--> 354\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m create_protobuf_for_task_2(\n\u001b[0;32m    355\u001b[0m         input_run, filtered_ground_truth_spoilers\n\u001b[0;32m    356\u001b[0m     )\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    357\u001b[0m         ret[k \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m display_name] \u001b[39m=\u001b[39m v\n\u001b[0;32m    359\u001b[0m ret \u001b[39m=\u001b[39m to_prototext(ret)\n",
      "File \u001b[1;32m~\\UNI\\VI\\nlp\\project\\clickbait-spoiling\\src\\evaluation.py:329\u001b[0m, in \u001b[0;36mcreate_protobuf_for_task_2\u001b[1;34m(actual, expected)\u001b[0m\n\u001b[0;32m    322\u001b[0m         missing_predictions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    323\u001b[0m         y_pred \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    325\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mresult-size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlen\u001b[39m(keys),\n\u001b[0;32m    327\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbleu-score\u001b[39m\u001b[39m\"\u001b[39m: bleu_score(y_true, y_pred),\n\u001b[0;32m    328\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbert-score\u001b[39m\u001b[39m\"\u001b[39m: bert_score(y_true, y_pred),\n\u001b[1;32m--> 329\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmeteor-score\u001b[39m\u001b[39m\"\u001b[39m: meteor_score(y_true, y_pred),\n\u001b[0;32m    330\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmissing-predictions\u001b[39m\u001b[39m\"\u001b[39m: missing_predictions,\n\u001b[0;32m    331\u001b[0m }\n",
      "File \u001b[1;32m~\\UNI\\VI\\nlp\\project\\clickbait-spoiling\\src\\evaluation.py:292\u001b[0m, in \u001b[0;36mmeteor_score\u001b[1;34m(truth, prediction)\u001b[0m\n\u001b[0;32m    277\u001b[0m         preds\u001b[39m.\u001b[39mwrite(p \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m cmd \u001b[39m=\u001b[39m [\n\u001b[0;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mjava\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    281\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m-Xmx2G\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madq\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    291\u001b[0m ]\n\u001b[1;32m--> 292\u001b[0m meteor_output \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mcheck_output(cmd)\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(meteor_output\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mFinal score:\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip())\n",
      "File \u001b[1;32mc:\\Users\\zgawrysi\\Anaconda3\\envs\\dl\\lib\\subprocess.py:421\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m         empty \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    419\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[1;32m--> 421\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39mpopenargs, stdout\u001b[39m=\u001b[39mPIPE, timeout\u001b[39m=\u001b[39mtimeout, check\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    422\u001b[0m            \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[1;32mc:\\Users\\zgawrysi\\Anaconda3\\envs\\dl\\lib\\subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m     retcode \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mpoll()\n\u001b[0;32m    525\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m retcode:\n\u001b[1;32m--> 526\u001b[0m         \u001b[39mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[39m.\u001b[39margs,\n\u001b[0;32m    527\u001b[0m                                  output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m CompletedProcess(process\u001b[39m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['java', '-Xmx2G', '-jar', '/meteor-1.5.jar', 'C:\\\\Users\\\\zgawrysi\\\\AppData\\\\Local\\\\Temp\\\\tmpcc9yg6n1/truths.txt', 'C:\\\\Users\\\\zgawrysi\\\\AppData\\\\Local\\\\Temp\\\\tmpcc9yg6n1/preds.txt', '-l', 'en', '-norm', '-t', 'adq']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%run src/evaluation.py --input_run \"data/test_output.jsonl\" --ground_truth_spoilers \"data/test_true.jsonl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our approach\n",
    "Retraining roberta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
